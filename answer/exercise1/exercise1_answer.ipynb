{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science 2025\n",
    "\n",
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 | Matrix warm-up\n",
    "<span style=\"background-color: #ccfff2\"> *Note: You can find tutorials for NumPy and Pandas under 'Useful tutorials' in the course material.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful properties of any scientific programming language (Python with NumPy, R, Julia, etc) is that they allow us to work with matrices efficiently. Let's learn more about these features!\n",
    "\n",
    "### 1.1 Basics\n",
    "\n",
    "1. Let's start by creating two arrays <span style=\"background-color: #ccfff2\"> A</span> and <span style=\"background-color: #ccfff2\"> B</span> which each have the integers <span style=\"background-color: #ccfff2\"> 0, 1, 2, ..., 1e7-1</span>. Use the normal arrays or lists of the programming language you are using, e.g. *list* or *[ ]* or *numpy.array()* in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =  [      0       1       2 ... 9999997 9999998 9999999]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#create array with elements in the range from 0 to 1e7 - 1 (integers)\n",
    "A = np.arange(int(1e7))\n",
    "B = np.arange(int(1e7))\n",
    "\n",
    "print('A = ', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function that uses a <span style=\"background-color: #ccfff2\"> for loop</span> or equivalent to return a new array <span style=\"background-color: #ccfff2\"> C</span>, which contains the <span style=\"background-color: #ccfff2\"> element-wise sum of *A* and *B*</span>, e.g. C should contain the integers <span style=\"background-color: #ccfff2\"> 0, 2, 4, etc</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  [0.0000000e+00 2.0000000e+00 4.0000000e+00 ... 1.9999994e+07 1.9999996e+07\n",
      " 1.9999998e+07]\n"
     ]
    }
   ],
   "source": [
    "def add_with_for(A,B):\n",
    "    C = np.zeros(len(A)) # initialize new array\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        C[i] = A[i] + B[i] # element-wise sum\n",
    "    return C\n",
    "\n",
    "print('C = ', add_with_for(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, let's create another function that uses NumPy (or equivalent) to do the same. To try it out, allocate two arrays (e.g. using <span style=\"background-color: #ccfff2\"> np.array</span> in NumPy) and add the arrays together using your function. Don't use loops, instead, find out how to add the two arrays directly. What do you notice in comparison to the previous function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  [       0        2        4 ... 19999994 19999996 19999998]\n"
     ]
    }
   ],
   "source": [
    "C = np.add(A,B)\n",
    "print('C = ', C) # Wow! So much faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Array manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #ccfff2\"> *Note: for the following exercises, only use NumPy or equivalent functions. Don't use any loops.* </span>\n",
    "1. Create the following array:\n",
    "\n",
    "*[hint: <span style=\"background-color: #ccfff2\"> np.reshape</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
    "#        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "#        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "#        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
    "#        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
    "#        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
    "#        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
    "#        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "#        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
    "#        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr = \n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.arange(100) #Set elements in the range from 0 to 99\n",
    "\n",
    "arr1 = arr1.reshape((10,10)) #Reshape the array to have dimensions (10,10)\n",
    "\n",
    "print('arr = ')\n",
    "print(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr = \n",
      "[[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Use this cell for your code\n",
    "arr2 = np.array([0.,1.])\n",
    "\n",
    "arr2 = np.tile(arr2, 50) #repeat pattern 50 times\n",
    "\n",
    "arr2 = arr2.reshape((10,10)) #reshape to desired dimensions (10,10)\n",
    "\n",
    "print('arr = ')\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create the following array (D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D = \n",
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "D = np.ones((10,10)) # Create a (10,10) array consisting only of ones\n",
    "\n",
    "np.fill_diagonal(D, 0) # Switch all the elements of the diagonal to zero\n",
    "\n",
    "print('D = ')\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the following array (E):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E = \n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "E = np.rot90(D)\n",
    "\n",
    "print('E = ')\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Call the last two matrices <span style=\"background-color: #ccfff2\">D</span> and <span style=\"background-color: #ccfff2\">E</span>, respectively. Show that the determinant of their product (matrix multiplication) is the same as the product of their determinants. That is calculate both <span style=\"background-color: #ccfff2\">det(DE)</span> and <span style=\"background-color: #ccfff2\">det(D) * det(E)</span>, and show that they are the same. Is it a coincidence? (I think not) The product of the determinants (or the determinant of the product) should be -81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-81.0\n",
      "-81.00000000000017\n"
     ]
    }
   ],
   "source": [
    "D_det = np.linalg.det(D) # determinant of D\n",
    "\n",
    "E_det = np.linalg.det(E) # determinant of E\n",
    "\n",
    "print(D_det * E_det)\n",
    "\n",
    "prod = np.dot(D, E) #product matrix\n",
    "\n",
    "prod_det = np.linalg.det(prod) #determinant of product matrix\n",
    "\n",
    "print(prod_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the distributive property of the determinant. It is an algebraic property such that the determinant of the product of two matrices is equal to the product of the determinant of each matrix separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Slicing\n",
    "\n",
    "Array slicing is a powerful way to extract data from an array. Let's practice array slicing with the following exercises!\n",
    "\n",
    "1. Load the [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). The data should be a matrix of shape <span style=\"background-color: #ccfff2\">(20640, 8)</span>, that is 20640 rows and 8 columns. Use the <span style=\"background-color: #ccfff2\">.shape</span> attribute of NumPy arrays to verify this. Here's a [description of the fields](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. rubric:: References\n",
      "\n",
      "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "  Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "cali = fetch_california_housing()\n",
    "\n",
    "print(cali.data.shape) # print dataset shape\n",
    "print(cali['DESCR']) # print dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select rows where the average number of bedrooms <span style=\"background-color: #ccfff2\">(AveBedrms)</span> is higher than 2. The first few row indices should be <span style=\"background-color: #ccfff2\">710,  1023,  1024, ...</span> (zero-indexed). Count these houses - how many rows are selected? *[hint: <span style=\"background-color: #ccfff2\">np.where</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houses with more bedrooms (row indices) =  (array([  710,  1023,  1024,  1030,  1102,  1233,  1234,  1235,  1236,\n",
      "        1238,  1239,  1240,  1566,  1867,  1871,  1872,  1879,  1881,\n",
      "        1889,  1901,  1906,  1910,  1911,  1912,  1913,  1914,  1925,\n",
      "        1926,  1978,  1979,  2392,  2395,  2396,  2397,  2398,  2510,\n",
      "        2511,  2643,  2656,  2763,  2768,  2776,  2778,  3014,  3086,\n",
      "        3095,  3258,  3292,  3293,  3313,  3314,  3334,  3349,  3350,\n",
      "        9193,  9423,  9431,  9451,  9634,  9669,  9671,  9672,  9675,\n",
      "        9676,  9678,  9679,  9680,  9681,  9682,  9683, 10067, 10076,\n",
      "       10077, 10078, 10079, 10080, 10081, 10082, 10083, 10084, 10405,\n",
      "       11705, 11706, 11707, 11708, 11709, 11710, 11711, 11713, 11714,\n",
      "       11715, 11716, 11717, 11719, 11720, 11721, 11722, 11723, 11724,\n",
      "       11725, 11729, 11831, 11832, 11833, 11834, 11847, 11848, 11849,\n",
      "       11850, 11862, 11865, 11866, 11867, 11869, 11870, 12136, 12303,\n",
      "       12305, 12306, 12307, 12324, 12325, 12344, 12349, 12351, 12354,\n",
      "       12359, 12361, 12362, 12366, 12368, 12371, 12372, 12374, 12376,\n",
      "       12390, 12392, 12394, 12396, 12404, 12405, 12430, 12446, 12447,\n",
      "       13898, 13900, 13911, 13912, 13919, 13920, 13923, 13924, 13934,\n",
      "       13935, 13936, 13937, 13939, 13940, 13941, 13942, 13943, 13944,\n",
      "       13945, 13946, 13947, 13948, 13949, 13950, 13953, 13954, 13955,\n",
      "       13956, 13957, 13958, 13959, 13960, 13961, 13962, 13963, 13964,\n",
      "       13965, 13966, 13967, 13968, 13969, 13970, 13971, 13972, 13973,\n",
      "       13974, 13975, 13976, 13978, 13979, 13980, 13999, 14417, 14418,\n",
      "       14805, 15500, 15595, 15779, 16598, 17878, 17891, 18680, 18681,\n",
      "       18817, 18821, 18822, 18858, 19331, 19362, 19435, 19536, 19736,\n",
      "       19780, 19781, 19789, 19800, 19801, 19802, 19803, 19806, 19807,\n",
      "       19975, 19976, 19977, 20089, 20092, 20093, 20094, 20110, 20112,\n",
      "       20113]),)\n",
      "Number of houses (rows) with more bedrooms =  235\n"
     ]
    }
   ],
   "source": [
    "# Find row indices where average number of bedrooms > 2\n",
    "houses = np.where(cali.data[:, 3] > 2)\n",
    "\n",
    "houses_count = houses[0].shape[0] # Count rows\n",
    "\n",
    "print('Houses with more bedrooms (row indices) = ', houses)\n",
    "print('Number of houses (rows) with more bedrooms = ', houses_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select the rows where the median house age (i.e. median in each block group) <span style=\"background-color: #ccfff2\">(HouseAge)</span> is between 1 and 3 years (inclusive). There should be **124** of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houses selected within HouseAge interval (row indices) =  (array([   59,   854,   871,   959,   976,  1260,  1565,  1566,  1648,\n",
      "        1719,  2206,  2310,  2311,  2312,  2336,  2339,  2706,  2774,\n",
      "        2993,  3130,  3140,  5506,  9109,  9132,  9147,  9168,  9187,\n",
      "        9378,  9639, 10336, 10376, 10391, 10401, 10403, 10406, 10410,\n",
      "       10412, 10416, 10440, 10456, 10467, 10513, 10514, 10519, 10521,\n",
      "       10524, 10525, 10529, 10548, 10619, 10622, 10631, 11490, 11775,\n",
      "       12000, 12006, 12077, 12084, 12119, 12123, 12137, 12142, 12143,\n",
      "       12151, 12156, 12167, 12171, 12201, 12202, 12203, 12204, 12285,\n",
      "       12286, 12308, 12363, 12430, 12841, 12868, 13041, 13074, 13100,\n",
      "       13102, 13139, 13177, 13179, 13367, 13368, 13373, 13374, 13375,\n",
      "       13422, 13659, 13713, 13715, 13747, 13848, 13855, 14557, 15220,\n",
      "       15444, 15464, 15736, 15785, 16383, 16566, 16593, 17068, 17824,\n",
      "       17826, 17827, 18725, 18942, 18947, 18972, 18989, 19001, 19003,\n",
      "       19033, 19046, 19536, 19561, 19650, 20070, 20367]),)\n",
      "Number of houses (rows) within HouseAge interval =  124\n"
     ]
    }
   ],
   "source": [
    "house_age = np.where((cali.data[:, 1] >= 1)&(cali.data[:, 1] <= 3))\n",
    "\n",
    "print('Houses selected within HouseAge interval (row indices) = ', house_age)\n",
    "print('Number of houses (rows) within HouseAge interval = ', house_age[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the mean of the block group population <span style=\"background-color: #ccfff2\">(Population)</span> for homes whose median value is more than 25000 USD (the target variable). It should be around **1425.68**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean block group population =  1425.6833737275813\n"
     ]
    }
   ],
   "source": [
    "homes = np.where(cali.target > 0.25) # Houses with median value over $25,000\n",
    "\n",
    "pop = cali.data[homes, 4] # From the selected rows, get the population column\n",
    "\n",
    "mean_pop = np.mean(pop) # calculate mean of population\n",
    "\n",
    "print(\"Mean block group population = \", mean_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 | Working with text data\n",
    "\n",
    "Next, let's look into some text data. We will be looking into Amazon reviews, and the necessary steps to transform a raw dataset into a format more suitable for prediction tasks.\n",
    "\n",
    "1. Download the automotive 5-core dataset from [here](https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Automotive_5.json.gz). Next, you can extract the data in <span style=\"background-color: #ccfff2\">JSON</span> format. You can also download one of the bigger ones, if you are feeling ambitious. Open the JSON file. Access the <span style=\"background-color: #ccfff2\">reviewText</span> field, which contains the unstructured review text written by the user.\n",
    "\n",
    "For instance, the first review reads as follows: \n",
    "\n",
    "*'After I wrote the below review, the manufacturer contacted me and explained how to use this.  Instead of the (current) picture on Amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally. [...]'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A review example:  It sucks barely picks up anything definitely not for cars or pretty much anything don't waste your money\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "data = pd.read_json(\"Automotive_5.json\", lines=True)\n",
    "\n",
    "print('A review example: ', data.iloc[1]['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, let's follow some steps to normalize the text data.\n",
    "\n",
    "When dealing with natural language, it is important to notice that while, for example, the words \"Copper\" and \"copper\" are represented by two different strings, they have the same meaning. When applying statistical methods on this data, it is useful to ensure that words with the same meaning are represented by the same string.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Downcasing</span>: Let's first downcase the contents of the <span style=\"background-color: #ccfff2\">reviewText</span> field.\n",
    "\n",
    "Now the first review should be:\n",
    "\n",
    "*'after i wrote the below review, the manufacturer contacted me and explained how to use this.  instead of the (current) picture on amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally.'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcasing example:  it sucks barely picks up anything definitely not for cars or pretty much anything dont waste your money\n"
     ]
    }
   ],
   "source": [
    "data['reviewText'] = data['reviewText'].str.lower()\n",
    "\n",
    "print('Downcasing example: ', data.iloc[1]['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's continue with punctuation and stop word removal. Stop words are words like \"and\", \"the\", etc. They are usually very common words that have little to do with the actual content matter. There's plenty openly available lists of stop words for almost any (natural) language.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Punctuation and stop-word removal</span>: Let's now remove all punctuation, as well as the stop words. You can find a stop word list for English, e.g. [here](https://gist.github.com/xldrkp/4a3b1a33f10d37bedbe0068f2b4482e8#file-stopwords-en-txt).*(use the link to download a txt of english stopwords)* Save the stopwords in the file as \"stopwords-en.txt\".\n",
    "\n",
    "First review at this point reads as: \n",
    "\n",
    "*'wrote review manufacturer contacted explained current picture amazon phone vertically stand phone horizontally'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example after removing punctuation:  it sucks barely picks up anything definitely not for cars or pretty much anything dont waste your money\n"
     ]
    }
   ],
   "source": [
    "data['reviewText'] = data['reviewText'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "\n",
    "print('Example after removing punctuation: ', data.iloc[1]['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stopwords-en.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#remove stop words\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopwords-en.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     stopwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (stopwords)]))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stopwords-en.txt'"
     ]
    }
   ],
   "source": [
    "#remove stop words\n",
    "with open(\"stopwords-en.txt\") as f:\n",
    "    stopwords = set(f.read().split(\"\\n\"))\n",
    "    \n",
    "data[\"reviewText\"] = data['reviewText'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stopwords)]))\n",
    "print('Example after removing stopwords: ', data.iloc[1]['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's continue with stemming. For example, while the words \"swims\" and \"swim\" are different strings, they both refer to swimming. [Stemming](https://en.wikipedia.org/wiki/Stemming) refers to the process of mapping words from their inflected form to their base form, for instance: swims -> swim.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Stemming</span>: Apply a stemmer on the paragraphs, so that inflected forms are mapped to the base form. For example, for Python the popular natural language toolkit [nltk](http://www.nltk.org/howto/stem.html) has an easy to use stemmer. In case you are using R, you can try the [Snowball stemmer](https://www.rdocumentation.org/packages/corpus/versions/0.10.2/topics/stem_snowball). You can find out how to install nltk from [here](https://www.nltk.org/install.html). It will take a while to run! So, grab a coffee and wait :D\n",
    "\n",
    "Finally, after stemming: \n",
    "\n",
    "*'wrote review manufactur contact explain current pictur amazon phone vertic stand phone horizont'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "ps = PorterStemmer() # Takes a while\n",
    "data[\"reviewText\"] = data[\"reviewText\"].apply(lambda x: ' '.join([ps.stem(word) for word in str(x).split()]))\n",
    "\n",
    "print('Review example after stemming: ', data.iloc[1]['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally, filter the data by selecting reviews where the field <span style=\"background-color: #ccfff2\">overall</span> is 4 or 5, and store the review texts in a file named <span style=\"background-color: #ccfff2\">pos.txt</span>. Similarly, select reviews with rating 1 or 2 and store them in a file named <span style=\"background-color: #ccfff2\">neg.txt</span>. Ignore the reviews with overall rating 3. Each line in the two files should contain exactly one preprocessed review text without the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 4505: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         neg\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39miloc[row][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 11\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pos))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(neg))\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 4505: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "\n",
    "for row in range(len(data)):\n",
    "    if data.iloc[row][\"overall\"] > 3:\n",
    "        pos.append(data.iloc[row][\"reviewText\"])\n",
    "    elif data.iloc[row][\"overall\"] < 3:\n",
    "        neg.append(data.iloc[row][\"reviewText\"])\n",
    "\n",
    "with open(\"pos.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(pos))\n",
    "\n",
    "with open(\"neg.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(neg))\n",
    "    \n",
    "# Check the generated files!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 | SQL basics\n",
    "\n",
    "Next, let's take a refresher on the basics of SQL. In this exercise, you will be working on the simplified Northwind 2000 SQLite database. You can download the database from Kaggle [here](https://courses.mooc.fi/api/v0/files/course/f92ffc32-2dd4-421d-87f3-c48800422cc5/files/VEKX2bxGCDGyojG902gmYZTXCnrAQw.zip).\n",
    "\n",
    "To test your SQL queries and complete the exercise, you can download and install SQLite if you don't yet have it installed.\n",
    "\n",
    "Please write SQL queries for the tasks on the simplified Northwind 2000 SQLite database.\n",
    "\n",
    "1. List the first name, last name, and hire date of all employees hired after January 1st, 1994.\n",
    "\n",
    "2. Count how many orders each customer has placed.\n",
    "\n",
    "3. Find the names of all customers who have ordered the product \"Chai\".\n",
    "\n",
    "4. Find all orders that have been placed but not yet shipped.\n",
    "\n",
    "5. Find the customer who has placed the most orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your solutions. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences. Remember to also submit your SQL queries. No need to submit the text files for the programming exercises.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. List the first name, last name, and hire date of all employees hired after January 1st, 1994.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  FirstName,\n",
    "  LastName,\n",
    "  HireDate\n",
    "FROM\n",
    "  Employees\n",
    "WHERE\n",
    "  HireDate > '1994-01-01';\n",
    "```\n",
    "\n",
    "2. Count how many orders each customer has placed.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  c.ContactName,\n",
    "  COUNT(o.OrderID) AS number_of_orders\n",
    "FROM\n",
    "  Customers AS c\n",
    "  JOIN Orders AS o ON c.CustomerID = o.CustomerID\n",
    "GROUP BY\n",
    "  c.CustomerID\n",
    "ORDER BY\n",
    "  number_of_orders DESC;\n",
    "```\n",
    "\n",
    "3. Find the names of all customers who have ordered the product \"Chai\".\n",
    "\n",
    "```sql\n",
    "SELECT DISTINCT\n",
    "  c.ContactName\n",
    "FROM\n",
    "  Customers AS c\n",
    "  JOIN Orders AS o ON c.CustomerID = o.CustomerID\n",
    "  JOIN OrderDetails AS od ON o.OrderID = od.OrderID\n",
    "  JOIN Products AS p ON od.ProductID = p.ProductID\n",
    "WHERE\n",
    "  p.ProductName = 'Chai';\n",
    "```\n",
    "\n",
    "4. Find all orders that have been placed but not yet shipped.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  OrderID,\n",
    "  CustomerID,\n",
    "  OrderDate\n",
    "FROM\n",
    "  Orders\n",
    "WHERE\n",
    "  ShippedDate IS NULL;\n",
    "```\n",
    "\n",
    "5. Find the customer who has placed the most orders.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  c.ContactName,\n",
    "  COUNT(o.OrderID) AS order_count\n",
    "FROM\n",
    "  Customers AS c\n",
    "  JOIN Orders AS o ON c.CustomerID = o.CustomerID\n",
    "GROUP BY\n",
    "  c.CustomerID\n",
    "ORDER BY\n",
    "  order_count DESC\n",
    "LIMIT 1;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
